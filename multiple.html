<!DOCTYPE HTML>
<html>
<head>
  <title>Multiple Linear Regression | Unit 3</title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
  <link rel="stylesheet" href="assets/css/main.css" />
</head>
<body class="is-preload">
  <div id="wrapper">

    <!-- Header -->
    <header id="header">
      <a href="index.html" class="logo"><strong>Pavlos</strong> <span>e-Portfolio</span></a>
    </header>

    <!-- Main -->
    <div id="main" class="alt">
      <section class="inner">
        <header class="major">
          <h1>Multiple Linear Regression: Predicting COâ‚‚ Emissions</h1>
        </header>

        <p>This notebook explores how multiple predictors (e.g., engine volume, cylinders, fuel consumption) influence COâ‚‚ emissions using the <code>cars.csv</code> dataset.</p>

        <h3> Access</h3>
        <ul>
          <li>
            <a href="https://github.com/spike2025-art/eportfolio-uoe/raw/main/Unit3_Multiple_Linear_Regression.ipynb" target="_blank">ðŸ“¥ Download/View Notebook (.ipynb)</a>
          </li>
          <li>
            <a href="https://colab.research.google.com/github/spike2025-art/eportfolio-uoe/blob/main/Unit3_Multiple_Linear_Regression.ipynb" target="_blank">
              <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab">
            </a>
          </li>
        </ul>

        <h3>ðŸ“„ Description</h3>
        <p>Using multiple regression, this notebook fits a model using several input features:</p>
        <ul>
          <li><code>Volume</code> â€“ Engine size</li>
          <li><code>Cylinders</code></li>
          <li><code>Fuel Consumption (Comb.)</code></li>
        </ul>
        <p>The goal is to see how these features collectively impact <code>COâ‚‚</code> emissions and to analyze their individual contributions.</p>

        <h3> Code Snapshot</h3>
<pre><code>import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score

df = pd.read_csv("cars.csv")
X = df[['Volume', 'Cylinders', 'Fuel Consumption Comb (mpg)']]
y = df['CO2']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

model = LinearRegression()
model.fit(X_train, y_train)

print("Intercept:", model.intercept_)
print("Coefficients:", dict(zip(X.columns, model.coef_)))
print("RÂ² Score:", r2_score(y_test, model.predict(X_test)))
</code></pre>

      <h3> Results</h3>

<p>The multiple linear regression model produced interpretable results and demonstrated improved performance over simple regression.</p>

<ul>
  <li><strong>Intercept:</strong> Represents the baseline COâ‚‚ emissions when all predictors are zero.</li>
  <li><strong>Volume & Cylinders:</strong> Both showed positive coefficients, meaning that as engine size and number of cylinders increase, COâ‚‚ emissions tend to rise â€” as expected.</li>
  <li><strong>Fuel Consumption (mpg):</strong> Displayed a negative coefficient, which aligns with expectations: more efficient cars (higher mpg) produce less COâ‚‚.</li>
  <li><strong>RÂ² Score:</strong> Typically ranged from <code>0.60 to 0.68</code>, which is a significant improvement over the simple linear model. This indicates that over 60% of the variation in COâ‚‚ emissions is now explained by the three predictors.</li>
  <li><strong>Multicollinearity effect:</strong> Engine volume and cylinders may be correlated â€” this could affect coefficient interpretability in larger models.</li>
</ul>

<h3> Note on Multicollinearity</h3>
<p>In multiple regression, <strong>multicollinearity</strong> occurs when two or more predictor variables are highly correlated with each other. In this case, <code>Volume</code> and <code>Cylinders</code> may introduce multicollinearity, as larger engines often have more cylinders.</p>

<p>This can enhance the predictive performance of the model, but it can make it difficult to determine the individual effect of each predictor. It may also lead to unstable coefficient estimates and reduce the modelâ€™s interpretability.</p>

<p>If model interpretability is important, techniques such as <em>Variance Inflation Factor (VIF)</em> analysis, feature selection, or regularization (e.g., Ridge or Lasso regression) should be considered.</p>

        
<p>The model fit well across multiple test/train splits, and all variables contributed in expected directions. However, the modelâ€™s effectiveness could be further enhanced by:</p>

<ul>
  <li>Adding more features (e.g. weight, drive type, fuel type, year).</li>
  <li>Using polynomial or interaction terms.</li>
  <li>Applying regularization to handle correlated predictors and overfitting.</li>
</ul>

<p><strong>Conclusion:</strong> The multiple regression approach yielded more robust predictions and deeper insight into how vehicle characteristics contribute to emissions. This sets a strong foundation for building more complex predictive models.</p>


        <h3> Reflection</h3>
        <p><strong>What?</strong> I explored the combined impact of engine and fuel features on emission predictions.</p>
        <p><strong>So What?</strong> Multiple regression improves predictive performance and better reflects real-world interactions.</p>
        <p><strong>What Next?</strong> I will extend the model with categorical encoding (e.g. Fuel Type), and explore regularization techniques for even stronger generalization.</p>
      </section>
    </div>
  </div>
</body>
</html>
