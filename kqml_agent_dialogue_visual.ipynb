{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KQML/KIF Agent Dialogue System\n",
    "## Interactive Multi-Agent Communication Demonstration\n",
    "\n",
    "**Agents:**\n",
    "- Alice: Procurement agent (queries stock availability)\n",
    "- Bob: Warehouse inventory agent (manages stock information)\n",
    "\n",
    "**Communication Standards:**\n",
    "- KQML (Knowledge Query and Manipulation Language)\n",
    "- KIF (Knowledge Interchange Format)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import FancyBboxPatch, FancyArrowPatch\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional\n",
    "from dataclasses import dataclass, asdict\n",
    "from enum import Enum\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. KQML Performative Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KQMLPerformative(Enum):\n",
    "    ASK_IF = \"ask-if\"\n",
    "    ASK_ONE = \"ask-one\"\n",
    "    ASK_ALL = \"ask-all\"\n",
    "    TELL = \"tell\"\n",
    "    REPLY = \"reply\"\n",
    "    SORRY = \"sorry\"\n",
    "    ADVERTISE = \"advertise\"\n",
    "    SUBSCRIBE = \"subscribe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. KIF Knowledge Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KIFExpression:\n",
    "    @staticmethod\n",
    "    def predicate(name: str, *args) -> str:\n",
    "        args_str = \" \".join(str(arg) for arg in args)\n",
    "        return f\"({name} {args_str})\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def and_expression(*predicates) -> str:\n",
    "        preds_str = \" \".join(predicates)\n",
    "        return f\"(and {preds_str})\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def exists(variable: str, expression: str) -> str:\n",
    "        return f\"(exists ({variable}) {expression})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. KQML Message Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class KQMLMessage:\n",
    "    performative: KQMLPerformative\n",
    "    sender: str\n",
    "    receiver: str\n",
    "    content: str\n",
    "    reply_with: Optional[str] = None\n",
    "    in_reply_to: Optional[str] = None\n",
    "    language: str = \"KIF\"\n",
    "    ontology: str = \"warehouse-inventory\"\n",
    "    timestamp: str = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.timestamp is None:\n",
    "            self.timestamp = datetime.now().isoformat()\n",
    "    \n",
    "    def to_kqml_string(self) -> str:\n",
    "        lines = [f\"({self.performative.value}\"]\n",
    "        lines.append(f\"  :sender {self.sender}\")\n",
    "        lines.append(f\"  :receiver {self.receiver}\")\n",
    "        lines.append(f\"  :content \\\"{self.content}\\\"\")\n",
    "        \n",
    "        if self.reply_with:\n",
    "            lines.append(f\"  :reply-with {self.reply_with}\")\n",
    "        if self.in_reply_to:\n",
    "            lines.append(f\"  :in-reply-to {self.in_reply_to}\")\n",
    "        \n",
    "        lines.append(f\"  :language {self.language}\")\n",
    "        lines.append(f\"  :ontology {self.ontology}\")\n",
    "        lines.append(\")\")\n",
    "        \n",
    "        return \"\\n\".join(lines)\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return self.to_kqml_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Product Database (Knowledge Base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductDatabase:\n",
    "    def __init__(self):\n",
    "        self.inventory = {\n",
    "            \"tv-50inch-samsung\": {\n",
    "                \"type\": \"television\",\n",
    "                \"brand\": \"Samsung\",\n",
    "                \"size\": \"50inch\",\n",
    "                \"hdmi_slots\": 4,\n",
    "                \"stock_level\": 15,\n",
    "                \"available\": True,\n",
    "                \"price\": 599.99\n",
    "            },\n",
    "            \"tv-50inch-lg\": {\n",
    "                \"type\": \"television\",\n",
    "                \"brand\": \"LG\",\n",
    "                \"size\": \"50inch\",\n",
    "                \"hdmi_slots\": 3,\n",
    "                \"stock_level\": 8,\n",
    "                \"available\": True,\n",
    "                \"price\": 549.99\n",
    "            },\n",
    "            \"tv-50inch-sony\": {\n",
    "                \"type\": \"television\",\n",
    "                \"brand\": \"Sony\",\n",
    "                \"size\": \"50inch\",\n",
    "                \"hdmi_slots\": 4,\n",
    "                \"stock_level\": 0,\n",
    "                \"available\": False,\n",
    "                \"price\": 649.99\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def query_stock_level(self, product_id: str) -> Optional[int]:\n",
    "        if product_id in self.inventory:\n",
    "            return self.inventory[product_id][\"stock_level\"]\n",
    "        return None\n",
    "    \n",
    "    def query_property(self, product_id: str, property_name: str) -> Optional[Any]:\n",
    "        if product_id in self.inventory:\n",
    "            return self.inventory[product_id].get(property_name)\n",
    "        return None\n",
    "    \n",
    "    def query_products_by_criteria(self, **criteria) -> List[Dict]:\n",
    "        matching_products = []\n",
    "        \n",
    "        for product_id, properties in self.inventory.items():\n",
    "            match = True\n",
    "            for key, value in criteria.items():\n",
    "                if properties.get(key) != value:\n",
    "                    match = False\n",
    "                    break\n",
    "            \n",
    "            if match:\n",
    "                product_info = {\"product_id\": product_id, **properties}\n",
    "                matching_products.append(product_info)\n",
    "        \n",
    "        return matching_products\n",
    "\n",
    "db = ProductDatabase()\n",
    "df_inventory = pd.DataFrame.from_dict(db.inventory, orient='index')\n",
    "print(\"\\nðŸ“¦ Current Inventory:\")\n",
    "display(df_inventory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Agent Base Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        self.message_counter = 0\n",
    "        self.conversation_history: List[KQMLMessage] = []\n",
    "    \n",
    "    def generate_message_id(self) -> str:\n",
    "        self.message_counter += 1\n",
    "        return f\"{self.name.lower()}-msg-{self.message_counter:03d}\"\n",
    "    \n",
    "    def send_message(self, message: KQMLMessage) -> None:\n",
    "        self.conversation_history.append(message)\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"[{self.name} â†’ {message.receiver}] @ {message.timestamp}\")\n",
    "        print('='*70)\n",
    "        print(message.to_kqml_string())\n",
    "        print()\n",
    "    \n",
    "    def receive_message(self, message: KQMLMessage) -> Optional[KQMLMessage]:\n",
    "        self.conversation_history.append(message)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Alice Agent (Procurement Agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AliceAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Alice\")\n",
    "        self.required_hdmi_slots = 4\n",
    "        self.evaluated_products = []\n",
    "    \n",
    "    def ask_about_50inch_tv_stock(self, receiver: str) -> KQMLMessage:\n",
    "        kif_content = KIFExpression.and_expression(\n",
    "            KIFExpression.predicate(\"type\", \"?product\", \"television\"),\n",
    "            KIFExpression.predicate(\"size\", \"?product\", \"50inch\"),\n",
    "            KIFExpression.predicate(\"available\", \"?product\", \"true\"),\n",
    "            KIFExpression.predicate(\"stock-level\", \"?product\", \"?quantity\")\n",
    "        )\n",
    "        \n",
    "        message = KQMLMessage(\n",
    "            performative=KQMLPerformative.ASK_ALL,\n",
    "            sender=self.name,\n",
    "            receiver=receiver,\n",
    "            content=kif_content,\n",
    "            reply_with=self.generate_message_id()\n",
    "        )\n",
    "        \n",
    "        return message\n",
    "    \n",
    "    def ask_about_hdmi_slots(self, receiver: str, product_id: str, \n",
    "                            in_reply_to: str) -> KQMLMessage:\n",
    "        kif_content = KIFExpression.predicate(\n",
    "            \"hdmi-slots\", \n",
    "            product_id, \n",
    "            \"?num_slots\"\n",
    "        )\n",
    "        \n",
    "        message = KQMLMessage(\n",
    "            performative=KQMLPerformative.ASK_ONE,\n",
    "            sender=self.name,\n",
    "            receiver=receiver,\n",
    "            content=kif_content,\n",
    "            reply_with=self.generate_message_id(),\n",
    "            in_reply_to=in_reply_to\n",
    "        )\n",
    "        \n",
    "        return message\n",
    "    \n",
    "    def evaluate_product(self, product_info: Dict) -> bool:\n",
    "        hdmi_slots = product_info.get(\"hdmi_slots\", 0)\n",
    "        stock_level = product_info.get(\"stock_level\", 0)\n",
    "        meets_requirements = hdmi_slots >= self.required_hdmi_slots and stock_level > 0\n",
    "        \n",
    "        self.evaluated_products.append({\n",
    "            'product_id': product_info.get('product_id', 'Unknown'),\n",
    "            'brand': product_info.get('brand', 'Unknown'),\n",
    "            'hdmi_slots': hdmi_slots,\n",
    "            'stock_level': stock_level,\n",
    "            'price': product_info.get('price', 0),\n",
    "            'meets_requirements': meets_requirements\n",
    "        })\n",
    "        \n",
    "        return meets_requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Bob Agent (Warehouse Inventory Agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BobAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Bob\")\n",
    "        self.database = ProductDatabase()\n",
    "    \n",
    "    def receive_message(self, message: KQMLMessage) -> Optional[KQMLMessage]:\n",
    "        super().receive_message(message)\n",
    "        \n",
    "        if message.performative == KQMLPerformative.ASK_ALL:\n",
    "            return self.handle_ask_all(message)\n",
    "        elif message.performative == KQMLPerformative.ASK_ONE:\n",
    "            return self.handle_ask_one(message)\n",
    "        else:\n",
    "            return KQMLMessage(\n",
    "                performative=KQMLPerformative.SORRY,\n",
    "                sender=self.name,\n",
    "                receiver=message.sender,\n",
    "                content=\"(unsupported-performative)\",\n",
    "                in_reply_to=message.reply_with\n",
    "            )\n",
    "    \n",
    "    def handle_ask_all(self, message: KQMLMessage) -> KQMLMessage:\n",
    "        products = self.database.query_products_by_criteria(\n",
    "            type=\"television\",\n",
    "            size=\"50inch\",\n",
    "            available=True\n",
    "        )\n",
    "        \n",
    "        if products:\n",
    "            product_statements = []\n",
    "            for product in products:\n",
    "                product_id = product[\"product_id\"]\n",
    "                stock = product[\"stock_level\"]\n",
    "                brand = product[\"brand\"]\n",
    "                \n",
    "                statement = KIFExpression.and_expression(\n",
    "                    KIFExpression.predicate(\"product-id\", product_id),\n",
    "                    KIFExpression.predicate(\"brand\", brand),\n",
    "                    KIFExpression.predicate(\"stock-level\", product_id, stock),\n",
    "                    KIFExpression.predicate(\"available\", product_id, \"true\")\n",
    "                )\n",
    "                product_statements.append(statement)\n",
    "            \n",
    "            kif_response = \" \".join(product_statements)\n",
    "        else:\n",
    "            kif_response = \"(no-matching-products)\"\n",
    "        \n",
    "        response = KQMLMessage(\n",
    "            performative=KQMLPerformative.REPLY,\n",
    "            sender=self.name,\n",
    "            receiver=message.sender,\n",
    "            content=kif_response,\n",
    "            in_reply_to=message.reply_with\n",
    "        )\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def handle_ask_one(self, message: KQMLMessage) -> KQMLMessage:\n",
    "        content = message.content\n",
    "        \n",
    "        if \"hdmi-slots\" in content:\n",
    "            parts = content.strip(\"()\").split()\n",
    "            if len(parts) >= 2:\n",
    "                product_id = parts[1]\n",
    "                \n",
    "                hdmi_slots = self.database.query_property(\n",
    "                    product_id, \n",
    "                    \"hdmi_slots\"\n",
    "                )\n",
    "                \n",
    "                if hdmi_slots is not None:\n",
    "                    kif_response = KIFExpression.predicate(\n",
    "                        \"hdmi-slots\",\n",
    "                        product_id,\n",
    "                        hdmi_slots\n",
    "                    )\n",
    "                else:\n",
    "                    kif_response = \"(unknown-product)\"\n",
    "            else:\n",
    "                kif_response = \"(invalid-query)\"\n",
    "        else:\n",
    "            kif_response = \"(unsupported-query)\"\n",
    "        \n",
    "        response = KQMLMessage(\n",
    "            performative=KQMLPerformative.REPLY,\n",
    "            sender=self.name,\n",
    "            receiver=message.sender,\n",
    "            content=kif_response,\n",
    "            in_reply_to=message.reply_with\n",
    "        )\n",
    "        \n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_message_flow(messages: List[KQMLMessage]):\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    alice_x, bob_x = 2, 8\n",
    "    y_spacing = 1.5\n",
    "    start_y = len(messages) * y_spacing\n",
    "    \n",
    "    ax.add_patch(FancyBboxPatch((alice_x - 0.8, start_y + 0.5), 1.6, 1, \n",
    "                                boxstyle=\"round,pad=0.1\", \n",
    "                                facecolor='lightblue', edgecolor='navy', linewidth=2))\n",
    "    ax.text(alice_x, start_y + 1, 'ALICE\\n(Procurement)', \n",
    "            ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    ax.add_patch(FancyBboxPatch((bob_x - 0.8, start_y + 0.5), 1.6, 1, \n",
    "                                boxstyle=\"round,pad=0.1\", \n",
    "                                facecolor='lightcoral', edgecolor='darkred', linewidth=2))\n",
    "    ax.text(bob_x, start_y + 1, 'BOB\\n(Warehouse)', \n",
    "            ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    ax.plot([alice_x, alice_x], [0, start_y + 0.5], 'b--', linewidth=1.5, alpha=0.5)\n",
    "    ax.plot([bob_x, bob_x], [0, start_y + 0.5], 'r--', linewidth=1.5, alpha=0.5)\n",
    "    \n",
    "    colors = {'ask-all': '#3498db', 'ask-one': '#2ecc71', 'reply': '#e74c3c', 'sorry': '#95a5a6'}\n",
    "    \n",
    "    for idx, msg in enumerate(messages):\n",
    "        y_pos = start_y - (idx + 1) * y_spacing\n",
    "        \n",
    "        if msg.sender == \"Alice\":\n",
    "            start_x, end_x = alice_x, bob_x\n",
    "            direction = 'right'\n",
    "        else:\n",
    "            start_x, end_x = bob_x, alice_x\n",
    "            direction = 'left'\n",
    "        \n",
    "        color = colors.get(msg.performative.value, '#34495e')\n",
    "        \n",
    "        arrow = FancyArrowPatch((start_x, y_pos), (end_x, y_pos),\n",
    "                               arrowstyle='->', mutation_scale=20, \n",
    "                               linewidth=2.5, color=color, alpha=0.8)\n",
    "        ax.add_patch(arrow)\n",
    "        \n",
    "        label = f\"{msg.performative.value.upper()}\"\n",
    "        label_x = (start_x + end_x) / 2\n",
    "        ax.text(label_x, y_pos + 0.3, label, \n",
    "               ha='center', va='bottom', fontsize=9, \n",
    "               bbox=dict(boxstyle='round,pad=0.3', facecolor='white', edgecolor=color, linewidth=1.5))\n",
    "    \n",
    "    ax.set_xlim(0, 10)\n",
    "    ax.set_ylim(-1, start_y + 2)\n",
    "    ax.axis('off')\n",
    "    ax.set_title('Agent Communication Flow Diagram', fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    legend_elements = [mpatches.Patch(facecolor=colors[k], label=k.upper()) \n",
    "                      for k in colors.keys()]\n",
    "    ax.legend(handles=legend_elements, loc='upper right', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_inventory_status(database: ProductDatabase):\n",
    "    df = pd.DataFrame.from_dict(database.inventory, orient='index')\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    \n",
    "    brands = df['brand'].values\n",
    "    stock = df['stock_level'].values\n",
    "    colors_stock = ['green' if s > 0 else 'red' for s in stock]\n",
    "    axes[0].barh(brands, stock, color=colors_stock, alpha=0.7, edgecolor='black')\n",
    "    axes[0].set_xlabel('Stock Level', fontsize=11, fontweight='bold')\n",
    "    axes[0].set_title('Stock Availability by Brand', fontsize=12, fontweight='bold')\n",
    "    axes[0].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    hdmi = df['hdmi_slots'].values\n",
    "    colors_hdmi = ['#2ecc71' if h >= 4 else '#e74c3c' for h in hdmi]\n",
    "    axes[1].bar(brands, hdmi, color=colors_hdmi, alpha=0.7, edgecolor='black')\n",
    "    axes[1].axhline(y=4, color='blue', linestyle='--', linewidth=2, label='Requirement (4 slots)')\n",
    "    axes[1].set_ylabel('HDMI Slots', fontsize=11, fontweight='bold')\n",
    "    axes[1].set_title('HDMI Slots Comparison', fontsize=12, fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    prices = df['price'].values\n",
    "    axes[2].scatter(prices, stock, s=hdmi*100, c=colors_stock, alpha=0.6, edgecolors='black', linewidth=2)\n",
    "    for i, brand in enumerate(brands):\n",
    "        axes[2].annotate(brand, (prices[i], stock[i]), \n",
    "                        xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "    axes[2].set_xlabel('Price ($)', fontsize=11, fontweight='bold')\n",
    "    axes[2].set_ylabel('Stock Level', fontsize=11, fontweight='bold')\n",
    "    axes[2].set_title('Price vs Stock (size=HDMI slots)', fontsize=12, fontweight='bold')\n",
    "    axes[2].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_evaluation_results(alice: AliceAgent):\n",
    "    if not alice.evaluated_products:\n",
    "        print(\"No products evaluated yet.\")\n",
    "        return\n",
    "    \n",
    "    df = pd.DataFrame(alice.evaluated_products)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    meets = df['meets_requirements'].value_counts()\n",
    "    colors_pie = ['#2ecc71', '#e74c3c']\n",
    "    labels_pie = ['Meets Requirements', 'Does Not Meet']\n",
    "    axes[0, 0].pie(meets.values, labels=labels_pie, autopct='%1.1f%%', \n",
    "                   colors=colors_pie, startangle=90, textprops={'fontsize': 11})\n",
    "    axes[0, 0].set_title('Product Evaluation Summary', fontsize=13, fontweight='bold')\n",
    "    \n",
    "    df_sorted = df.sort_values('meets_requirements', ascending=False)\n",
    "    colors_bar = ['green' if m else 'red' for m in df_sorted['meets_requirements']]\n",
    "    axes[0, 1].barh(df_sorted['brand'], df_sorted['hdmi_slots'], color=colors_bar, alpha=0.7, edgecolor='black')\n",
    "    axes[0, 1].axvline(x=4, color='blue', linestyle='--', linewidth=2, label='Min Requirement')\n",
    "    axes[0, 1].set_xlabel('HDMI Slots', fontsize=11, fontweight='bold')\n",
    "    axes[0, 1].set_title('HDMI Slots vs Requirements', fontsize=13, fontweight='bold')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    x = np.arange(len(df))\n",
    "    width = 0.35\n",
    "    axes[1, 0].bar(x - width/2, df['hdmi_slots'], width, label='HDMI Slots', alpha=0.8, color='skyblue', edgecolor='black')\n",
    "    axes[1, 0].bar(x + width/2, df['stock_level']/2, width, label='Stock/2', alpha=0.8, color='lightcoral', edgecolor='black')\n",
    "    axes[1, 0].set_xlabel('Products', fontsize=11, fontweight='bold')\n",
    "    axes[1, 0].set_ylabel('Value', fontsize=11, fontweight='bold')\n",
    "    axes[1, 0].set_title('HDMI Slots vs Stock Level', fontsize=13, fontweight='bold')\n",
    "    axes[1, 0].set_xticks(x)\n",
    "    axes[1, 0].set_xticklabels(df['brand'], rotation=45)\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    suitable = df[df['meets_requirements'] == True]\n",
    "    if len(suitable) > 0:\n",
    "        axes[1, 1].bar(suitable['brand'], suitable['price'], \n",
    "                      color='#3498db', alpha=0.7, edgecolor='black')\n",
    "        axes[1, 1].set_ylabel('Price ($)', fontsize=11, fontweight='bold')\n",
    "        axes[1, 1].set_title('Price Comparison (Suitable Products)', fontsize=13, fontweight='bold')\n",
    "        axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        for i, (brand, price) in enumerate(zip(suitable['brand'], suitable['price'])):\n",
    "            axes[1, 1].text(i, price + 10, f'${price:.2f}', \n",
    "                          ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "    else:\n",
    "        axes[1, 1].text(0.5, 0.5, 'No suitable products found', \n",
    "                       ha='center', va='center', transform=axes[1, 1].transAxes,\n",
    "                       fontsize=12, color='red', fontweight='bold')\n",
    "        axes[1, 1].set_title('Price Comparison (Suitable Products)', fontsize=13, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_conversation_timeline(messages: List[KQMLMessage]):\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    performatives = [msg.performative.value for msg in messages]\n",
    "    senders = [msg.sender for msg in messages]\n",
    "    \n",
    "    perf_counts = pd.Series(performatives).value_counts()\n",
    "    \n",
    "    x = np.arange(len(messages))\n",
    "    colors_map = {'Alice': '#3498db', 'Bob': '#e74c3c'}\n",
    "    colors = [colors_map.get(s, 'gray') for s in senders]\n",
    "    \n",
    "    ax.scatter(x, [1]*len(messages), s=300, c=colors, alpha=0.7, edgecolors='black', linewidth=2)\n",
    "    \n",
    "    for i, (msg, sender) in enumerate(zip(messages, senders)):\n",
    "        ax.annotate(f\"{msg.performative.value}\\n({sender})\", \n",
    "                   (i, 1), xytext=(0, -30 if i % 2 == 0 else 30), \n",
    "                   textcoords='offset points', ha='center',\n",
    "                   fontsize=8, bbox=dict(boxstyle='round,pad=0.3', \n",
    "                   facecolor=colors[i], alpha=0.3, edgecolor='black'),\n",
    "                   arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0', lw=1.5))\n",
    "    \n",
    "    ax.set_ylim(0.5, 1.5)\n",
    "    ax.set_xlim(-0.5, len(messages) - 0.5)\n",
    "    ax.set_xlabel('Message Sequence', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Conversation Timeline', fontsize=14, fontweight='bold')\n",
    "    ax.set_yticks([])\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                                  markerfacecolor=colors_map[k], \n",
    "                                  markersize=10, label=k) for k in colors_map.keys()]\n",
    "    ax.legend(handles=legend_elements, loc='upper right', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"âœ“ Visualization functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Dialogue Coordinator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueCoordinator:\n",
    "    def __init__(self):\n",
    "        self.alice = AliceAgent()\n",
    "        self.bob = BobAgent()\n",
    "        self.all_messages: List[KQMLMessage] = []\n",
    "    \n",
    "    def deliver_message(self, sender: Agent, message: KQMLMessage, \n",
    "                       receiver: Agent) -> Optional[KQMLMessage]:\n",
    "        sender.send_message(message)\n",
    "        self.all_messages.append(message)\n",
    "        \n",
    "        response = receiver.receive_message(message)\n",
    "        \n",
    "        if response:\n",
    "            receiver.send_message(response)\n",
    "            self.all_messages.append(response)\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def run_dialogue(self) -> None:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"AGENT DIALOGUE SIMULATION: ALICE AND BOB\")\n",
    "        print(\"Scenario: Stock Procurement Query\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        print(\"\\n[STEP 1] Alice queries available 50-inch televisions...\")\n",
    "        msg1 = self.alice.ask_about_50inch_tv_stock(\"Bob\")\n",
    "        response1 = self.deliver_message(self.alice, msg1, self.bob)\n",
    "        \n",
    "        print(\"\\n[STEP 2] Alice processes inventory information...\")\n",
    "        \n",
    "        if response1 and response1.performative == KQMLPerformative.REPLY:\n",
    "            available_products = self.bob.database.query_products_by_criteria(\n",
    "                type=\"television\",\n",
    "                size=\"50inch\",\n",
    "                available=True\n",
    "            )\n",
    "            \n",
    "            print(f\"\\nAlice found {len(available_products)} available product(s)\")\n",
    "            \n",
    "            print(\"\\n[STEP 3] Alice queries HDMI specifications...\")\n",
    "            \n",
    "            for product in available_products:\n",
    "                product_id = product[\"product_id\"]\n",
    "                \n",
    "                msg_hdmi = self.alice.ask_about_hdmi_slots(\n",
    "                    \"Bob\", \n",
    "                    product_id,\n",
    "                    response1.reply_with or \"\"\n",
    "                )\n",
    "                response_hdmi = self.deliver_message(\n",
    "                    self.alice, \n",
    "                    msg_hdmi, \n",
    "                    self.bob\n",
    "                )\n",
    "                \n",
    "                if self.alice.evaluate_product(product):\n",
    "                    print(f\"\\nâœ“ {product_id} meets requirements!\")\n",
    "                    print(f\"  - Brand: {product['brand']}\")\n",
    "                    print(f\"  - HDMI Slots: {product['hdmi_slots']}\")\n",
    "                    print(f\"  - Stock Level: {product['stock_level']}\")\n",
    "                    print(f\"  - Price: ${product['price']}\")\n",
    "                else:\n",
    "                    print(f\"\\nâœ— {product_id} does not meet requirements\")\n",
    "                    print(f\"  - HDMI Slots: {product['hdmi_slots']} \" +\n",
    "                          f\"(Required: {self.alice.required_hdmi_slots})\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"DIALOGUE SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"Total messages exchanged: {len(self.all_messages)}\")\n",
    "        print(f\"Alice sent: {len(self.alice.conversation_history)} messages\")\n",
    "        print(f\"Bob sent: {len(self.bob.conversation_history)} messages\")\n",
    "        print(\"\\nDialogue completed successfully!\")\n",
    "        print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Initial Inventory Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_db = ProductDatabase()\n",
    "print(\"\\nðŸ“Š INITIAL WAREHOUSE INVENTORY STATUS\")\n",
    "print(\"=\"*70)\n",
    "visualize_inventory_status(temp_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Run Agent Dialogue Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinator = DialogueCoordinator()\n",
    "coordinator.run_dialogue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Message Flow Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“ˆ AGENT COMMUNICATION FLOW DIAGRAM\")\n",
    "print(\"=\"*70)\n",
    "visualize_message_flow(coordinator.all_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Conversation Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nâ±ï¸ CONVERSATION TIMELINE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "visualize_conversation_timeline(coordinator.all_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Product Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸŽ¯ ALICE'S PRODUCT EVALUATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "visualize_evaluation_results(coordinator.alice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Final Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“Š DETAILED STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "msg_data = []\n",
    "for msg in coordinator.all_messages:\n",
    "    msg_data.append({\n",
    "        'Sender': msg.sender,\n",
    "        'Receiver': msg.receiver,\n",
    "        'Performative': msg.performative.value,\n",
    "        'Timestamp': msg.timestamp[:19]\n",
    "    })\n",
    "\n",
    "df_messages = pd.DataFrame(msg_data)\n",
    "print(\"\\nðŸ“¨ Message Exchange Log:\")\n",
    "display(df_messages)\n",
    "\n",
    "print(\"\\nðŸ“‹ Performative Distribution:\")\n",
    "perf_dist = df_messages['Performative'].value_counts()\n",
    "display(perf_dist)\n",
    "\n",
    "if coordinator.alice.evaluated_products:\n",
    "    df_eval = pd.DataFrame(coordinator.alice.evaluated_products)\n",
    "    print(\"\\nðŸŽ¯ Product Evaluation Summary:\")\n",
    "    display(df_eval)\n",
    "    \n",
    "    suitable = df_eval[df_eval['meets_requirements'] == True]\n",
    "    print(f\"\\nâœ… Products meeting requirements: {len(suitable)}/{len(df_eval)}\")\n",
    "    if len(suitable) > 0:\n",
    "        best_product = suitable.loc[suitable['price'].idxmin()]\n",
    "        print(f\"\\nðŸ’° Best value product: {best_product['brand']}\")\n",
    "        print(f\"   Price: ${best_product['price']:.2f}\")\n",
    "        print(f\"   Stock: {best_product['stock_level']} units\")\n",
    "        print(f\"   HDMI Slots: {best_product['hdmi_slots']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LEARNING OUTCOMES DEMONSTRATED\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "âœ“ Agent-Based Computing Motivations:\n",
    "  - Autonomous decision making (Alice evaluates products)\n",
    "  - Distributed knowledge (Bob maintains inventory database)\n",
    "  - Communication and coordination between independent agents\n",
    "  - Goal-oriented behavior (procurement task completion)\n",
    "\n",
    "âœ“ Agent Communication Standards:\n",
    "  - KQML for message structure and speech acts\n",
    "  - KIF for knowledge representation\n",
    "  - Asynchronous message passing\n",
    "  - Conversation tracking with reply-with/in-reply-to\n",
    "\n",
    "âœ“ Agent Models:\n",
    "  - Reactive agents (Bob responds to queries)\n",
    "  - Deliberative agents (Alice reasons about requirements)\n",
    "  - Knowledge-based agents (both use structured databases)\n",
    "  - Collaborative multi-agent systems\n",
    "\n",
    "âœ“ Visual Analytics:\n",
    "  - Message flow diagrams\n",
    "  - Inventory status dashboards\n",
    "  - Product evaluation matrices\n",
    "  - Timeline analysis\n",
    "\"\"\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}